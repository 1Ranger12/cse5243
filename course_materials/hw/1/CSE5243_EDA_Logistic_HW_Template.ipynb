{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 5243 - Introduction to Data Mining\n",
    "## Homework 1: Exploratory Data Analysis\n",
    "- Semester: Fall 2022\n",
    "- Instructor: Greg Ryslik\n",
    "- Student Name: John Smith\n",
    "- name.#: smith.3\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Introduction\n",
    "\n",
    "This homework will focus on a modified version of the kaggle dataset \"Pima Indians Diabetes Database\". It can be found [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database). The overarching objective is to diagnostically predict whether or not a patient has diabetes based upon several other covariates. The full description is shown on the website.\n",
    "\n",
    "Your task will be to first:\n",
    "1) Do the prerequisite EDA to understand the data set you will be working on. \n",
    "\n",
    "2) Fit an appropriate logistic model and analyze it.\n",
    "\n",
    "While some of the questions have exact answers, a few others are more open to interpretation. However, what we're looking for is the correct thinking ana analysis. For the objective questions, while some points are awarded for \"the correct number\", the majority of the points will be awarded for a proper analysis and logical investigation.\n",
    "\n",
    "Note: The data has been modified in both some subtle and not-so-subtle ways. You're welcome to look at other previous work online (in kaggle, stack overflow, etc -- and in fact that's critical to learning how to write good code!) but be wary about just using other people's work. It would both be a violation of the academic code of conduct, but it may also lead you down the wrong path\n",
    "\n",
    "### Collaboration\n",
    "For this assignment, you should work as an individual. You may informally discuss ideas with classmates, but your work should be your own.\n",
    "\n",
    "\n",
    "### What you need to turn in:\n",
    "1)\tCode\n",
    "\n",
    "-\tFor this homework, the code is the Jupyter Notebook.  Use the provided Jupyter Notebook template, and fill in the appropriate information.\n",
    "-\tYou may use common Python libraries for I/O, data manipulation, data visualization, etc. (e.g., NumPy, Pandas, MatPlotLib,…  See reference below.) \n",
    "-\tYou may not use library operations that perform, in effect, the “core” computations for this homework (e.g., If the assignment is to write a K-Means algorithm, you may not use a library operation that, in effect, does the core work needed to implement a K-Means algorithm.).  When in doubt, ask the grader or instructor.\n",
    "-\tThe code must be written by you, and any significant code snips you found on the Internet and used to understand how to do your coding for the core functionality must be attributed.  (You do not need to attribute basic functionality – matrix operations, IO, etc.)\n",
    "-\tThe code must be commented sufficiently to allow a reader to understand the algorithm without reading the actual Python, step by step.\n",
    "-\tWhen in doubt, ask the grader or instructor.\n",
    "\n",
    "2)\tWritten Report\n",
    "-\tFor this homework, the report is the Jupyter Notebook.  The report should be well-written.  Please proof-read and remove spelling and grammar errors and typos.\n",
    "-\tThe report should discuss your analysis and observations. Key points and findings must be written in a style suitable for consumption by non-experts.  Present charts and graphs to support your observations. If you performed any data processing, cleaning, etc., please discuss it within the report.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1.\tOverall readability and organization of your report (10%)\n",
    "> -\tIs it well organized and does the presentation flow in a logical manner?\n",
    "> -\tAre there no grammar and spelling mistakes?\n",
    "> -\tDo the charts/graphs relate to the text?\n",
    "> -\tAre the summarized key points and findings understandable by non-experts?\n",
    "> -\tDo the Overview and Conclusions provide context for the entire exercise?\n",
    "2.\tDomain Understanding Phase (10%)\n",
    "> -\tDid you provide a reasonable level of information?\n",
    "3.\tData Understanding Phase (30%)\n",
    "> -\tDid you find novel and/or interesting insights, or did you solely focus on simple summarizations of the data?\n",
    "> -\tDid you draw and present potential conclusion or observations from your analysis of the data?\n",
    "> -\tDid the statistics and visualizations you used make sense in the context of the data?\n",
    "4.\tData Analysis Phase (40%)\n",
    "> -   Did you correctly do the data cleaning steps and perform the appropriate logistic regression.\n",
    "> -   Was your analysis of the significant variables appropriate.\n",
    "> -   How have you justified your feature transformation and/or feature creation steps.\n",
    "5.  Conclusions (10%)\n",
    "> -   Did you summarize appropriately your critical findings. \n",
    "> -   Did you provide appropriate conclusions and next steps.\n",
    "\n",
    "### How to turn in your work on Carmen:\n",
    "\n",
    "Submit to Carmen the Jupyter Notebook, the html print out of your Jupyter notebook, and any supporting files that you used to process and analyze this data. You do not need to include the input data.  All submitted files (code and/or report) except for the data should be archived in a *.zip file, and submitted via Carmen.  Use this naming convention:\n",
    " \n",
    "•\tProject1_Surname_DotNumber.zip\n",
    "\n",
    "The submitted file should be less than 10MB.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section 0: Setup\n",
    "- Add any needed imports, helper functions, etc., here.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 1 - Domain Understanding\n",
    "- Write a few paragraphs providing an overview of the data. Some questions you should consider are: Where did the data come from? What do the rows represent? Why and how was the data collected? Who might use this data? What types of questions might users be able to analyze with this data?\n",
    "- You should review the dataset description information on the webpage to get some context. Of course you will only have limited background on this topic (and you are not expected to become an expert), so do your best to imagine the context for the work, making reasonable assumptions as appropriate. At this stage, you are not analyzing individual attributes, but discussing the dataset in aggregate.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 2 - Data Understanding\n",
    "- Perform exploratory data analysis of the dataset by looking at individual attributes and/or combinations of attributes. You should focus on identifying and describing interesting observations and insights that you might uncover from the data.\n",
    "- You should not simply provide the basic EDA information for all attributes in the data (although that's a good first step!). Instead, you should focus on those that are more interesting or important, and provide some discussion of what you observe. Pay particular attention to potentially interesting bivariate (two-variable) relationships, as well as the relationship between each attribute and the outcome.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.1 - Describe the meaning and type of data for each feature.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.2 - Provide basic statistics for the attributes.\n",
    "- For example: counts, percentiles, mean, median, standard deviation. The statistics should be relevant for the type of attribute.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.3 - Visualize the most important or interesting attributes using appropriate techniques.\n",
    "- For each visualization, provide an interpretation explaining why it is appropriate or interesting. What does each visualization tell us?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.4 - Verify data quality: explain any missing values, duplicate data, or outliers.\n",
    "- What, if anything, do you need to do about these? Be specific.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.5 - Explore the relationships among the features, excluding the outcome attribute.\n",
    "- Use scatter plots, correlation matrices, cross-tabulations, group-wise averages, or other appropriate techniques. Explain and interpret any interesting relationships.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.6 - Identify and explain any interesting relationships between the outcome attribute and the other attributes.\n",
    "- You may refer to earlier visualizations or create new ones. Feel free to look at $\\chi^2$ values and other statsitics as you deem appropriate. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 3 - Data Analysis\n",
    "- Based on the insights gleaned in the data understanding step above, let's do some logistic regression modeling! \n",
    "- One of the final outputs should be a logistic regression model and interpration of the results.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.1. Data Prep\n",
    "- Let's assume all duplicate records are in fact false and remove them. \n",
    "- Outliers can be handled in a variety of ways including removing the observation, setting them to NA's (if you're algorithm allows missing data) or imputation -- just to name a few. Let's change all the outliers to the median value of that feature WITHIN the specfic outcome group.  When you compute the median, be sure to exclude the missing values.\n",
    "  > Why would we want to change it to the median value as opposed to the mean?\n",
    "- There's a variety of ways to handle missing data. Two of them is to either drop the entire record or impute the missing value. For this scenario we'll impute the record based upon the average value for that feature WITHIN that specific outcome group.\n",
    "\n",
    "  > Bonus points: When you fit the logistic regression, what might this imputation operation lead to in your conclusions when analyzing the logistic regression output? Be sure to consider the case for both outliers and missing data. How can yo verify that any erroneous conclusions are discovered eventually?\n",
    "\n",
    "### Output:\n",
    "- How any duplicate records are were there? Show a dataframe of which records were removed.\n",
    "\n",
    "\n",
    "- How many outliers were found? Show what they were and what value they were changed to.\n",
    "\n",
    "\n",
    "- Show the mean, median and std deviation of each feature after you remove duplicate records, adjust the outliers and fixed the missing values.\n",
    "\n",
    "\n",
    "- Have any of the critical visualizations or relationships you discovered in section 2 changed?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.2 - Did you decide to implement any freature transformations? If so, why?\n",
    "-  If you decided you wanted to change any features, describe why and how and for what purposes. Feel free (though not required) to use mathematical notation where appropriate after providing an explanation.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.3 - Did you decide to create any new features? If so, why?\n",
    "-  If you decided you wanted to create any features, describe why and how and for what purposes. Feel free (though not required) to use mathematical notation where appropriate after providing an explanation.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.4 - Fit a logistic regression model using the data before any transformations or additions (e.g., the data at the end of section 3.2)\n",
    "- Here we want to evaluate the model. Given an interpretation and an analysis.\n",
    "\n",
    "### Output:\n",
    "- Show the model output, coefficients, p-values and other relevant statistical information.\n",
    "- Provide the odds ratios of the significant parameters as well as an interpretation of that odd's ratio. Be sure to mention what level of significance you are using.\n",
    "- Assuming you use a cuttoff of $\\pi_i > 0.5$ when classifying diabetes what is your misclassification table.\n",
    "- Assuming you use a cutoff of $\\pi_i > 0.75$ when classifying diabetes what is your misclassification table.\n",
    "\n",
    "> Bonus: Plot an ROC curve and describe it. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.5 - Fit a logistic regression model using the data after your feature transformations and new variables. \n",
    "- Here we want to see if you were able to discover features that led to an improve moodel\n",
    "\n",
    "### Output:\n",
    "- Show the model output, coefficients, p-values and other relevant statistical information.\n",
    "- Provide the odds ratios of the significant parameters as well as an interpretation of that odd's ratio. Be sure to mention what level of significance you are using.\n",
    "- Assuming you use a cuttoff of $\\pi_i > 0.5$ when classifying diabetes what is your misclassification table.\n",
    "- Assuming you use a cutoff of $\\pi_i > 0.75$ when classifying diabetes what is your misclassification table.\n",
    "\n",
    "> Bonus: Plot an ROC curve and describe it. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 4 - Conclusions\n",
    "- What are your overall conclusions about the data?\n",
    "- What did you learn? What would you explore further with additional data, time or resources. What might \"future research\" require to gain deeper insight? \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
